{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cudf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e65cc36edcb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcudf\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cudf'"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import cv2\n",
    "import cudf as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from numpy import save\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9c92ec445a48d09b56251d3b959563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=738285.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"expanded_data_shuffled.csv\")\n",
    "\n",
    "face_scores_data = df[\"face_scores\"]\n",
    "\n",
    "face_filtered_data_paths = []\n",
    "face_scores_data = tqdm(face_scores_data)\n",
    "for index, score in enumerate(face_scores_data):\n",
    "    if score >= -1 and score<=100:\n",
    "        face_filtered_data_paths.append(str(df[\"path\"].iloc[index]))\n",
    "\n",
    "len(face_filtered_data_paths)\n",
    "\n",
    "len(face_filtered_data_paths)\n",
    "face_filtered_data_paths = np.array(face_filtered_data_paths)\n",
    "save(\"face_filtered_greater_4\",face_filtered_data_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "738285"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(face_filtered_data_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_count = 0#len(face_filtered_data_paths)\n",
    "while img_count<=len(face_filtered_data_paths):\n",
    "    if img_count<0:\n",
    "        img_count=0\n",
    "    img = cv.imread(face_filtered_data_paths[img_count])\n",
    "    cv.imshow(\"Face_img\",img)\n",
    "    key_pressed = cv.waitKey(0)\n",
    "    if key_pressed == ord('n'):\n",
    "        img_count += 1\n",
    "    elif key_pressed == ord('p'):\n",
    "        img_count -= 1\n",
    "    elif key_pressed == ord('q'):\n",
    "        break\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Review faces with Bounding boxes<\\h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "noface_count = 0\n",
    "oneface_count = 0\n",
    "twoface_count = 0\n",
    "face_count = 0\n",
    "face_cascade = cv.CascadeClassifier(cv.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv.data.haarcascades +'haarcascade_eye.xml')\n",
    "img_count = 0#len(face_filtered_data_paths)\n",
    "while img_count<len(face_filtered_data_paths):\n",
    "    if img_count<0:\n",
    "        img_count=0\n",
    "    img = cv2.imread(face_filtered_data_paths[img_count])\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.2, 10)\n",
    "    if len(faces) == 0:\n",
    "        noface_count+=1\n",
    "    elif len(faces) == 1:\n",
    "        oneface_count+=1\n",
    "    elif len(faces) == 2:\n",
    "        twoface_count+=1\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "    cv2.imshow(str(len(faces)),img)\n",
    "    face_count+=1\n",
    "    key_pressed = cv.waitKey(1)\n",
    "    if key_pressed == ord('n'):\n",
    "        img_count+=1\n",
    "    elif key_pressed == ord('p'):\n",
    "        img_count -= 1\n",
    "    elif key_pressed == ord('q'):\n",
    "        break\n",
    "#cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.873456790123457"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(noface_count+oneface_count+twoface_count)/(oneface_count+twoface_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Writing Croped images to Disk</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Run the below code to create a new DATA_FRAME</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_data = pd.read_csv(\"expanded_data_shuffled.csv\")\n",
    "cols = exp_data.columns\n",
    "filter_exp_data = pd.DataFrame(columns=cols)\n",
    "filter_exp_data.to_csv(\"croped_filter_expanded_data.csv\",index=False)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"expanded_data_shuffled.csv\")\n",
    "face_scores_data = df[\"face_scores\"]\n",
    "face_filtered_data_paths = []\n",
    "for index, score in enumerate(face_scores_data):\n",
    "    face_filtered_data_paths.append(str(df[\"path\"].iloc[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45aa0a33a79f4178a1b1c9dfd99f155e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=738285.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "face_cascade = cv.CascadeClassifier(cv.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "img_count = 0\n",
    "face_filtered_data_paths_tqdm = tqdm(face_filtered_data_paths)\n",
    "with open(\"croped_filter_expanded_data.csv\",\"w\") as new_df:\n",
    "    new_df_writer = csv.writer(new_df)\n",
    "    for index,path in enumerate(face_filtered_data_paths_tqdm):\n",
    "        img = cv2.imread(path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 10)\n",
    "        if len(faces)>=1:\n",
    "            img_data = list(exp_data.loc[index])\n",
    "            for i in faces[0]:\n",
    "                img_data.append(i)\n",
    "            new_df_writer.writerow(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Adding custom headers</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(exp_data.columns)\n",
    "cols.extend([\"x\",\"y\",\"w\",\"h\"])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['path', 'out_ages', 'out_genders', 'face_scores', 'x', 'y', 'w', 'h']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"croped_filter_expanded_data.csv\", names=cols)\n",
    "df.to_csv(\"croped_filter_expanded_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7817"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noface_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.336293729015487"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((oneface_count+twoface_count)*100)/(face_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_data = pd.read_csv(\"expanded_data_shuffled.csv\")\n",
    "cols = exp_data.columns\n",
    "#filter_exp_data = pd.DataFrame(columns=cols)\n",
    "#filter_exp_data.to_csv(\"filter_expanded_data.csv\",index=False)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"expanded_data_shuffled.csv\")\n",
    "face_scores_data = df[\"face_scores\"]\n",
    "face_filtered_data_paths = []\n",
    "for index, score in enumerate(face_scores_data):\n",
    "    face_filtered_data_paths.append(str(df[\"path\"].iloc[index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a267526ddcf416b8d35da2db1df7155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250813.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "face_cascade = cv.CascadeClassifier(cv.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "img_count = 0\n",
    "face_filtered_data_paths_tqdm = tqdm(face_filtered_data_paths)\n",
    "with open(\"filter_expanded_data.csv\",\"w\") as new_df:\n",
    "    new_df_writer = csv.writer(new_df)\n",
    "    for index,path in enumerate(face_filtered_data_paths_tqdm):\n",
    "        img = cv2.imread(path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        if len(faces)>=1:\n",
    "            new_df_writer.writerow(list(exp_data.loc[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv(\"filter_expanded_data.csv\",names=exp_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"filter_expanded_data.csv\",columns=exp_data.columns,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>out_genders</th>\n",
       "      <th>face_scores</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_ages</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>713</td>\n",
       "      <td>713</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>727</td>\n",
       "      <td>727</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>698</td>\n",
       "      <td>698</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>728</td>\n",
       "      <td>728</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>724</td>\n",
       "      <td>724</td>\n",
       "      <td>724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>728</td>\n",
       "      <td>728</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>755</td>\n",
       "      <td>755</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>705</td>\n",
       "      <td>705</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>776</td>\n",
       "      <td>776</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          path  out_genders  face_scores\n",
       "out_ages                                \n",
       "0          713          713          713\n",
       "1          727          727          727\n",
       "2          698          698          698\n",
       "3          728          728          728\n",
       "4          724          724          724\n",
       "...        ...          ...          ...\n",
       "94         674          674          674\n",
       "95         728          728          728\n",
       "96         755          755          755\n",
       "97         705          705          705\n",
       "98         776          776          776\n",
       "\n",
       "[99 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.groupby(\"out_ages\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Creating a CSV file with UTK croped images included<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"croped_filter_expanded_data-Copy2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Dataset-copy/imdb_faces/imdb_crop/04/nm0000404_rm1126270720_1937-12-21_2010.jpg'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"path\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Croped_image(img,bb_data):\n",
    "    img_shape = img.shape\n",
    "    #cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    x = bb_data[0]\n",
    "    y = bb_data[1]\n",
    "    w = bb_data[2]\n",
    "    h = bb_data[3]\n",
    "    crop_img = img[y:y+h, x:x+w]\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = [filepath for filepath in df[\"path\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "while index<len(df):\n",
    "    img_path = df[\"path\"][index]\n",
    "    bb_data = [df[\"x\"][index],df[\"y\"][index],df[\"w\"][index],df[\"h\"][index]]\n",
    "    img = cv2.imread(img_path)\n",
    "    img_croped = Get_Croped_image(img, bb_data)\n",
    "    cv2.imshow(\"image\", img_croped)\n",
    "    key_pressed = cv.waitKey(0)\n",
    "    if key_pressed == ord('n'):\n",
    "        index+=1\n",
    "    elif key_pressed == ord('p'):\n",
    "        index -= 1\n",
    "    elif key_pressed == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
