{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "#from wide_resnet import WideResNet\n",
    "from utils import load_data\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from mixup_generator import MixupGenerator\n",
    "from random_eraser import get_random_eraser\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from numpy import save, load\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, \\\n",
    "    GlobalMaxPool2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, Lambda\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_path = \"./Dataset-copy/imdb_faces/imdb_db.mat\"\n",
    "# image, gender, age, _, image_size, _ = load_data(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_resize(filepath, input_shape=(256, 256)):\n",
    "    im = Image.open((filepath)).convert('RGB')\n",
    "    im = im.resize(input_shape)\n",
    "    im_array = np.array(im, dtype=\"uint8\")#[..., ::-1]\n",
    "    return np.array(im_array / (np.max(im_array)+ 0.001), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.2,1.5],\n",
    "    zoom_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(im_array):\n",
    "    im_array = datagen.random_transform(im_array)\n",
    "    return im_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(df, batch_size=8, aug=False):\n",
    "    df = df.sample(frac=1)\n",
    "\n",
    "    dict_age = {'(0, 2)' : 0,\n",
    "                '(3, 5)' : 1,\n",
    "                '(6, 10)' : 2,\n",
    "                '(11, 15)' : 3,\n",
    "                '(16, 20)' : 4,\n",
    "                '(21, 30)' : 5,\n",
    "                '(31, 40)' : 6,\n",
    "                '(41, 50)' : 7,\n",
    "                '(51, 60)' : 8,\n",
    "                '(61, 70)' : 9,\n",
    "                '(71, 80)' : 10,\n",
    "                 '(81, 90)' : 11,\n",
    "                 '(91, 100)' : 12}\n",
    "\n",
    "    while True:\n",
    "        for i, batch in enumerate([df[i:i+batch_size] for i in range(0,df.shape[0],batch_size)]):\n",
    "            if aug:\n",
    "                images = np.array([augment(read_and_resize(file_path)) for file_path in batch.path.values])\n",
    "            else:\n",
    "                images = np.array([read_and_resize(file_path) for file_path in batch.path.values])\n",
    "\n",
    "\n",
    "            #labels = np.array([dict_age[g] for g in batch.out_ages.values])\n",
    "            labels = np.array(batch.out_ages.values)\n",
    "\n",
    "            labels = labels[..., np.newaxis]\n",
    "\n",
    "            yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_classes=1):\n",
    "\n",
    "    base_model = ResNet50(weights=\"./resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\", include_top=False)\n",
    "\n",
    "    #for layer in base_model.layers:\n",
    "    #    layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(100, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    if n_classes == 1:\n",
    "        x = Dense(n_classes, activation=\"sigmoid\")(x)\n",
    "    else:\n",
    "        x = Dense(n_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    base_model = Model(base_model.input, x, name=\"base_model\")\n",
    "    if n_classes == 1:\n",
    "        base_model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=optimizer)\n",
    "    else:\n",
    "        base_model.compile(loss=\"sparse_categorical_crossentropy\", metrics=['acc'], optimizer=optimizer)\n",
    "\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    base_path = \"./Dataset-copy/\"\n",
    "\n",
    "    dict_age = {'(0, 2)' : 0,\n",
    "                '(3, 5)' : 1,\n",
    "                '(6, 10)' : 2,\n",
    "                '(11, 15)' : 3,\n",
    "                '(16, 20)' : 4,\n",
    "                '(21, 30)' : 5,\n",
    "                '(31, 40)' : 6,\n",
    "                '(41, 50)' : 7,\n",
    "                '(51, 60)' : 8,\n",
    "                '(61, 70)' : 9,\n",
    "                '(71, 80)' : 10,\n",
    "                 '(81, 90)' : 11,\n",
    "                 '(91, 100)' : 12}\n",
    "\n",
    "    bag = 3\n",
    "\n",
    "    all_indexes = list(range(5))\n",
    "\n",
    "    accuracies = []\n",
    "    print(\"Reading train and test CSV files \")\n",
    "    train_df = pd.read_csv(\"imdb_dataset.csv\")\n",
    "    #test_df = pd.read_csv(\"test_gender_filtered_data_with_path.csv\")\n",
    "    tr_tr, tr_val = train_test_split(train_df, test_size=0.1,random_state = 100)\n",
    "    tr_val['out_ages'].groupby\n",
    "    print(\"Reading Done.\")\n",
    "    cnt_ave = 0\n",
    "    predictions = 0\n",
    "#     print(\"Extracting test labels and test images from files\")\n",
    "#     test_images = load(\"imdb_test_images.npy\")\n",
    "#     test_labels = load(\"imdb_test_labels.npy\")\n",
    "#     print(\"Extracting Done.\")\n",
    "    #tr_tr, tr_val = train_test_split(train_df, test_size=0.1,random_state = 100)\n",
    "    file_path = \"imdb_age_recog_weights.h5\"\n",
    "    \n",
    "    print(\"Generating callback_list\")\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    #early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)\n",
    "\n",
    "    reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "                                          mode=\"min\", \n",
    "                                          factor=0.1,\n",
    "                                          #cooldown=0,\n",
    "                                          patience=3,\n",
    "                                          verbose=1,\n",
    "                                          min_lr=0.00001)\n",
    "\n",
    "    callbacks_list = [checkpoint,\n",
    "                      reduce_on_plateau,\n",
    "                      #early\n",
    "                     ]  # early\n",
    "    print(\"Done Generating callbacklist.\")\n",
    "    print(\"generating Model\")\n",
    "    class_len = 13\n",
    "    print(\"Enter res for resuming else enter new\")\n",
    "    \n",
    "    model = get_model(n_classes=13)\n",
    "    print(\"Done generating model\")\n",
    "    print(\"Running Fit_generator\")\n",
    "    model.fit_generator(gen(tr_tr,batch_size=8, aug=True), \n",
    "                        validation_data=gen(tr_val), \n",
    "                        epochs=200, \n",
    "                        verbose=1, \n",
    "                        #workers=4,\n",
    "                        callbacks=callbacks_list,\n",
    "                        steps_per_epoch=500,#int(10740.75), \n",
    "                        validation_steps=50,\n",
    "                        #use_multiprocessing=True\n",
    "                       )\n",
    "    #model.save(file_path)\n",
    "    print(\"Trained Model saved to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y = model.pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train_df = pd.read_csv(\"imdb_dataset.csv\")\n",
    "tr_tr, tr_val = train_test_split(train_df, test_size=0.1,random_state = 100)\n",
    "tr_val, tr_test = train_test_split(tr_val,test_size=0.1,random_state = 100)\n",
    "test_images = np.array([read_and_resize(file_path) for file_path in tr_test.path.values])\n",
    "test_labels = np.array([file_path for file_path in tr_test.path.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "save(\"imdb_test_images.npy\",test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test_labels = np.array([int(g == \"m\") for g in tr_test.out_ages.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "save(\"imdb_test_labels.npy\",test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1719"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model = load_model(\"imdb_age_recog_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y_predict = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "index = 0\n",
    "prob_max_class = max(y_predict[index])\n",
    "age_class = np.where(y_predict[index] == prob_max_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_class[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dict_age = {'(0, 2)' : 0,\n",
    "                '(3, 5)' : 1,\n",
    "                '(6, 10)' : 2,\n",
    "                '(11, 15)' : 3,\n",
    "                '(16, 20)' : 4,\n",
    "                '(21, 30)' : 5,\n",
    "                '(31, 40)' : 6,\n",
    "                '(41, 50)' : 7,\n",
    "                '(51, 60)' : 8,\n",
    "                '(61, 70)' : 9,\n",
    "                '(71, 80)' : 10,\n",
    "                 '(81, 90)' : 11,\n",
    "                 '(91, 100)' : 12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-7a2fafe11b9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdict_age\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mage_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 6"
     ]
    }
   ],
   "source": [
    "dict_age[age_class[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
