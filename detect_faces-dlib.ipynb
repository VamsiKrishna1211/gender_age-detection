{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from numpy import save\n",
    "import time\n",
    "import csv\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8016be31e9404a79831e14dd0df9f68a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=738285.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"expanded_data_shuffled.csv\")\n",
    "\n",
    "face_scores_data = df[\"face_scores\"]\n",
    "\n",
    "face_filtered_data_paths = []\n",
    "face_scores_data = tqdm(face_scores_data)\n",
    "for index, score in enumerate(face_scores_data):\n",
    "    if score >= -1 and score<=100:\n",
    "        face_filtered_data_paths.append(str(df[\"path\"].iloc[index]))\n",
    "\n",
    "len(face_filtered_data_paths)\n",
    "\n",
    "len(face_filtered_data_paths)\n",
    "face_filtered_data_paths = np.array(face_filtered_data_paths)\n",
    "save(\"face_filtered_greater_4\",face_filtered_data_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "738285"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(face_filtered_data_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_count = 0#len(face_filtered_data_paths)\n",
    "while img_count<=len(face_filtered_data_paths):\n",
    "    if img_count<0:\n",
    "        img_count=0\n",
    "    img = cv.imread(face_filtered_data_paths[img_count])\n",
    "    cv.imshow(\"Face_img\",img)\n",
    "    key_pressed = cv.waitKey(0)\n",
    "    if key_pressed == ord('n'):\n",
    "        img_count += 1\n",
    "    elif key_pressed == ord('p'):\n",
    "        img_count -= 1\n",
    "    elif key_pressed == ord('q'):\n",
    "        break\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Review faces with Bounding boxes<\\h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) /io/opencv/modules/core/src/matrix.cpp:235: error: (-215:Assertion failed) s >= 0 in function 'setSize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-852cc6443c04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mblob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblobFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;31m#faces = dnnFaceDetector(img, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.2.0) /io/opencv/modules/core/src/matrix.cpp:235: error: (-215:Assertion failed) s >= 0 in function 'setSize'\n"
     ]
    }
   ],
   "source": [
    "noface_count = 0\n",
    "oneface_count = 0\n",
    "twoface_count = 0\n",
    "face_count = 0\n",
    "face_cascade = cv2.CascadeClassifier(cv.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv.data.haarcascades +'haarcascade_eye.xml')\n",
    "# dnnFaceDetector = dlib.cnn_face_detection_model_v1(\"./mmod_human_face_detector.dat\") \n",
    "modelFile = \"./opencv_face_detector_uint8.pb\"\n",
    "configFile = \"./opencv_face_detector.pbtxt\"\n",
    "net = cv2.dnn.readNetFromTensorflow(modelFile, configFile)\n",
    "img_count = 0#len(face_filtered_data_paths)\n",
    "while img_count<len(face_filtered_data_paths):\n",
    "    if img_count<0:\n",
    "        img_count=0\n",
    "    img = cv2.imread(face_filtered_data_paths[img_count])\n",
    "    #gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    img_shape = img.shape\n",
    "    im_means = list(cv2.mean(img))\n",
    "    im_means = [im_means[0],im_means[1],im_means[2]]\n",
    "    frameWidth = img_shape[0]\n",
    "    frameHeight = img_shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(img, 1.0, (img_shape[0], img_shape[1]), im_means, False, False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    #faces = dnnFaceDetector(img, 1)\n",
    "    if len(faces) == 0:\n",
    "        noface_count+=1\n",
    "    elif len(faces) == 1:\n",
    "        oneface_count+=1\n",
    "    elif len(faces) == 2:\n",
    "        twoface_count+=1\n",
    "    x=y=w=h=0\n",
    "    x1=y1=x2=y2=0\n",
    "#     for face in faces:\n",
    "#         x = face.rect.left()\n",
    "#         y = face.rect.top()\n",
    "#         w = face.rect.right()\n",
    "#         h = face.rect.bottom()\n",
    "    \n",
    "    for i in range(detections.shape[2]):\n",
    "\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        #if confidence > conf_threshold:\n",
    "\n",
    "        x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "\n",
    "        y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "\n",
    "        x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "        y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "    img = cv2.rectangle(img,(x1,y1),(x1+x2,y1+y2),(255,0,0),2)\n",
    "        #roi_gray = gray[y:y+h, x:x+w]\n",
    "        #roi_color = img[y:y+h, x:x+w]\n",
    "        #eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "#         for (ex,ey,ew,eh) in eyes:\n",
    "#             cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "    cv2.imshow(str(len(faces)),img)\n",
    "    face_count+=1\n",
    "    key_pressed = cv.waitKey(1)\n",
    "    if key_pressed == ord('n'):\n",
    "        img_count+=1\n",
    "    elif key_pressed == ord('p'):\n",
    "        img_count -= 1\n",
    "    elif key_pressed == ord('q'):\n",
    "        break\n",
    "#cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Writing Croped images to Disk</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_data = pd.read_csv(\"expanded_data_shuffled.csv\")\n",
    "cols = exp_data.columns\n",
    "filter_exp_data = pd.DataFrame(columns=cols)\n",
    "filter_exp_data.to_csv(\"croped_filter_expanded_data.csv\",index=False)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"expanded_data_shuffled.csv\")\n",
    "face_scores_data = df[\"face_scores\"]\n",
    "face_filtered_data_paths = []\n",
    "for index, score in enumerate(face_scores_data):\n",
    "    face_filtered_data_paths.append(str(df[\"path\"].iloc[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6e00c05b604ba291fe6a44f9534553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=738285.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-071dc57c6bfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mimg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "face_cascade = cv.CascadeClassifier(cv.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "img_count = 0\n",
    "face_filtered_data_paths_tqdm = tqdm(face_filtered_data_paths)\n",
    "with open(\"croped_filter_expanded_data.csv\",\"w\") as new_df:\n",
    "    new_df_writer = csv.writer(new_df)\n",
    "    for index,path in enumerate(face_filtered_data_paths_tqdm):\n",
    "        img = cv2.imread(path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        if len(faces)>=1:\n",
    "            img_data = list(exp_data.loc[index])\n",
    "            img_data.append(faces)\n",
    "            new_df_writer.writerow(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = (1,2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = [\"awcsf\",12431,423,3242]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis.append(list(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awcsf', 12431, 423, 3242, [1, 2, 3, 4]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7817"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noface_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.336293729015487"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((oneface_count+twoface_count)*100)/(face_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_data = pd.read_csv(\"expanded_data_shuffled.csv\")\n",
    "cols = exp_data.columns\n",
    "filter_exp_data = pd.DataFrame(columns=cols)\n",
    "filter_exp_data.to_csv(\"filter_expanded_data.csv\",index=False)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"expanded_data_shuffled.csv\")\n",
    "face_scores_data = df[\"face_scores\"]\n",
    "face_filtered_data_paths = []\n",
    "for index, score in enumerate(face_scores_data):\n",
    "    face_filtered_data_paths.append(str(df[\"path\"].iloc[index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a267526ddcf416b8d35da2db1df7155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250813.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dnnFaceDetector = dlib.cnn_face_detection_model_v1(\".dlib_face_recognition_resnet_model_v1.dat\")\n",
    "img_count = 0\n",
    "face_filtered_data_paths_tqdm = tqdm(face_filtered_data_paths)\n",
    "with open(\"filter_expanded_data.csv\",\"w\") as new_df:\n",
    "    new_df_writer = csv.writer(new_df)\n",
    "    for index,path in enumerate(face_filtered_data_paths_tqdm):\n",
    "        img = cv2.imread(path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        if len(faces)>=1:\n",
    "            new_df_writer.writerow(list(exp_data.loc[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exp_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-70922e74fb8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"croped_filter_expanded_data.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexp_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'exp_data' is not defined"
     ]
    }
   ],
   "source": [
    "new_df = pd.read_csv(\"croped_filter_expanded_data.csv\",names=exp_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(exp_data.columns)\n",
    "cols.append('face_loc')\n",
    "new_df.to_csv(\"croped_filter_expanded_data.csv\",columns=cols,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>out_genders</th>\n",
       "      <th>face_scores</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_ages</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>713</td>\n",
       "      <td>713</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>727</td>\n",
       "      <td>727</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>698</td>\n",
       "      <td>698</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>728</td>\n",
       "      <td>728</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>724</td>\n",
       "      <td>724</td>\n",
       "      <td>724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>728</td>\n",
       "      <td>728</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>755</td>\n",
       "      <td>755</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>705</td>\n",
       "      <td>705</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>776</td>\n",
       "      <td>776</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          path  out_genders  face_scores\n",
       "out_ages                                \n",
       "0          713          713          713\n",
       "1          727          727          727\n",
       "2          698          698          698\n",
       "3          728          728          728\n",
       "4          724          724          724\n",
       "...        ...          ...          ...\n",
       "94         674          674          674\n",
       "95         728          728          728\n",
       "96         755          755          755\n",
       "97         705          705          705\n",
       "98         776          776          776\n",
       "\n",
       "[99 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.groupby(\"out_ages\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"croped_filter_expanded_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
