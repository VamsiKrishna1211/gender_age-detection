{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    " \n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from numpy import save, load\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras import optimizers, losses, activations, models\n",
    "from tensorflow.keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, \\\n",
    "    GlobalMaxPool2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, Lambda, Conv2D\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K.set_floatx('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Croped_image(img,bb_data):\n",
    "    img_shape = img.shape\n",
    "    x = bb_data[0]\n",
    "    y = bb_data[1]\n",
    "    w = bb_data[2]\n",
    "    h = bb_data[3]\n",
    "    crop_img = img[y:y+h, x:x+w]\n",
    "    return crop_img\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.1)\n",
    "\n",
    "def augment(im_array):\n",
    "    im_array = datagen.random_transform(im_array)\n",
    "    return im_array\n",
    "\n",
    "\n",
    "def read_and_resize(dataFrame, input_shape=(224,224),aug=True):\n",
    "    #filepath = image_data.path.values[0]\n",
    "    images = []\n",
    "    for index in dataFrame.index :\n",
    "        im_cv = cv2.imread(dataFrame[\"path\"][index])\n",
    "        bb_data = (dataFrame[\"x\"][index],dataFrame[\"y\"][index],dataFrame[\"w\"][index],dataFrame[\"h\"][index])\n",
    "        im_cv = Get_Croped_image(im_cv,bb_data)\n",
    "        im_cv = cv2.resize(im_cv,input_shape)\n",
    "        im_array = np.array(im_cv)\n",
    "        im_cv = np.array(im_array / (np.max(im_array)+ 0.001))\n",
    "        if aug:\n",
    "            im_cv = augment(im_cv)\n",
    "        images.append(im_cv)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen(df, batch_size=4,input_shape=(64,64), aug=False):\n",
    "    df = df.sample(frac=1)\n",
    "    while True:\n",
    "        for _, batch in enumerate([df[i:i+batch_size] for i in range(0,df.shape[0],batch_size)]):\n",
    "            labels = np.array(batch.out_ages.values)\n",
    "            labels = labels[..., np.newaxis]    \n",
    "            images = np.array(read_and_resize(batch,aug=aug))\n",
    "            yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(optimizer,n_classes=1):\n",
    "\n",
    "#     base_model = keras.applications.nasnet.NASNetMobile(weights=\"./NASNet-mobile-no-top.h5\", include_top=False)\n",
    "\n",
    "#     #for layer in base_model.layers:\n",
    "#     #    layer.trainable = False\n",
    "\n",
    "#     x = base_model.output\n",
    "#     x = GlobalAveragePooling2D()(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     #x = Flatten()\n",
    "#     x = Dense(1000, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     x = Dense(750,activation=\"relu\")(x)\n",
    "#     x = Dense(350,activation=\"relu\")(x)\n",
    "#     x = Dense(100,activation=\"relu\")(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     if n_classes == 1:\n",
    "#         x = Dense(n_classes, activation=\"sigmoid\")(x)\n",
    "#     else:\n",
    "#         x = Dense(n_classes, activation=\"softmax\")(x)\n",
    "\n",
    "#     base_model = Model(base_model.input, x, name=\"base_model\")\n",
    "#     if n_classes == 1:\n",
    "#         base_model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=optimizer)\n",
    "#     else:\n",
    "#         base_model.compile(loss=\"sparse_categorical_crossentropy\", metrics=['acc'], optimizer=optimizer)\n",
    "\n",
    "    base_model = load_model(\"imdb_age_recog_weights.h5\")\n",
    "\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train and test CSV files \n",
      "Reading Done.\n",
      "Generating callback_list\n",
      "Done Generating callbacklist.\n",
      "generating Model\n",
      "WARNING:tensorflow:From /mnt/sda5/vamsik1211/Data/ML/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/sda5/vamsik1211/Data/ML/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done generating model\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    base_path = \"./Dataset-copy/\"\n",
    "\n",
    "    dict_age = {'(0, 2)' : 0,\n",
    "                '(3, 5)' : 1,\n",
    "                '(6, 10)' : 2,\n",
    "                '(11, 15)' : 3,\n",
    "                '(16, 20)' : 4,\n",
    "                '(21, 30)' : 5,\n",
    "                '(31, 40)' : 6,\n",
    "                '(41, 50)' : 7,\n",
    "                '(51, 60)' : 8,\n",
    "                '(61, 70)' : 9,\n",
    "                '(71, 80)' : 10,\n",
    "                 '(81, 90)' : 11,\n",
    "                 '(91, 100)' : 12}\n",
    "\n",
    "    bag = 3\n",
    "\n",
    "    all_indexes = list(range(5))\n",
    "    \n",
    "    accuracies = []\n",
    "    print(\"Reading train and test CSV files \")\n",
    "    train_df = pd.read_csv(\"croped_filter_expanded_data.csv\")\n",
    "    #test_df = pd.read_csv(\"test_gender_filtered_data_with_path.csv\")\n",
    "    tr_tr, tr_val = train_test_split(train_df, test_size=0.0005, random_state=100)\n",
    "    tr_unique_ages = tr_tr['out_ages'].unique()\n",
    "    tr_unique_ages.sort()\n",
    "    #print(\"Unique ages are: \",val_unique_ages)\n",
    "    print(\"Reading Done.\")\n",
    "    cnt_ave = 0\n",
    "    predictions = 0\n",
    "#     print(\"Extracting test labels and test images from files\")\n",
    "#     test_images = load(\"imdb_test_images.npy\")\n",
    "#     test_labels = load(\"imdb_test_labels.npy\")\n",
    "#     print(\"Extracting Done.\")\n",
    "    #tr_tr, tr_val = train_test_split(train_df, test_size=0.1,random_state = 100)\n",
    "    file_path = \"imdb_age_recog_weights.h5\"\n",
    "    \n",
    "    print(\"Generating callback_list\")\n",
    "    \n",
    "#     log_dir=\"./logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#     tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    #early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)\n",
    "\n",
    "    reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "                                          mode=\"min\", \n",
    "                                          factor=0.1,\n",
    "                                          #cooldown=0,\n",
    "                                          patience=7,\n",
    "                                          verbose=1,\n",
    "                                          min_lr=0.0000001)\n",
    "\n",
    "    tensorboard = TensorBoard(log_dir='./logs/imdb_age_recog')\n",
    "\n",
    "    callbacks_list = [checkpoint,\n",
    "                      reduce_on_plateau,\n",
    "                      tensorboard\n",
    "                      #tensorboard_callback\n",
    "                      #early\n",
    "                     ]  # early\n",
    "    \n",
    "    print(\"Done Generating callbacklist.\")\n",
    "    print(\"generating Model\")\n",
    "    optimizer = Adam(lr=0.0001)\n",
    "    model = get_model( optimizer,n_classes=99)\n",
    "    print(\"Done generating model\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fit_generator\n",
      "Epoch 1/200\n",
      "11593/11594 [============================>.] - ETA: 0s - loss: 0.8032 - acc: 0.7420Epoch 1/200\n",
      "  185/11594 [..............................] - ETA: 14:12 - loss: 0.8512 - acc: 0.7084\n",
      "Epoch 00001: val_acc improved from -inf to 0.70867, saving model to imdb_age_recog_weights.h5\n",
      "11594/11594 [==============================] - 10837s 935ms/step - loss: 0.8032 - acc: 0.7421 - val_loss: 0.8509 - val_acc: 0.7087\n",
      "Epoch 2/200\n",
      "11593/11594 [============================>.] - ETA: 0s - loss: 0.7694 - acc: 0.7526Epoch 1/200\n",
      "  186/11594 [..............................] - ETA: 8:42 - loss: 0.8768 - acc: 0.7038\n",
      "Epoch 00002: val_acc did not improve from 0.70867\n",
      "11594/11594 [==============================] - 10504s 906ms/step - loss: 0.7694 - acc: 0.7526 - val_loss: 0.8768 - val_acc: 0.7038\n",
      "Epoch 3/200\n",
      "11593/11594 [============================>.] - ETA: 0s - loss: 0.7388 - acc: 0.7629Epoch 1/200\n",
      "  186/11594 [..............................] - ETA: 10:21 - loss: 0.7631 - acc: 0.7527\n",
      "Epoch 00003: val_acc improved from 0.70867 to 0.75272, saving model to imdb_age_recog_weights.h5\n",
      "11594/11594 [==============================] - 10750s 927ms/step - loss: 0.7388 - acc: 0.7629 - val_loss: 0.7631 - val_acc: 0.7527\n",
      "Epoch 4/200\n",
      "11593/11594 [============================>.] - ETA: 0s - loss: 0.7110 - acc: 0.7716Epoch 1/200\n",
      "  186/11594 [..............................] - ETA: 9:53 - loss: 0.8594 - acc: 0.7310\n",
      "Epoch 00004: val_acc did not improve from 0.75272\n",
      "11594/11594 [==============================] - 10662s 920ms/step - loss: 0.7110 - acc: 0.7716 - val_loss: 0.8594 - val_acc: 0.7310\n",
      "Epoch 5/200\n",
      " 3144/11594 [=======>......................] - ETA: 2:09:18 - loss: 0.6819 - acc: 0.7809"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6133df787f48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#int(10740.75),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                         validation_steps=len(tr_val))\n\u001b[0m\u001b[1;32m     12\u001b[0m                         \u001b[0;31m#validation_data=((test_images), test_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0;31m#use_multiprocessing=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/sda5/vamsik1211/Data/ML/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/mnt/sda5/vamsik1211/Data/ML/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/sda5/vamsik1211/Data/ML/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/sda5/vamsik1211/Data/ML/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/mnt/sda5/vamsik1211/Data/ML/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Running Fit_generator\")\n",
    "batch_size = 32\n",
    "input_shape=(64,64)\n",
    "model.fit_generator(gen(tr_tr,batch_size=batch_size, aug=True), \n",
    "                        validation_data=gen(tr_val), \n",
    "                        epochs=200, \n",
    "                        verbose=1, \n",
    "                        #workers=4,\n",
    "                        callbacks=callbacks_list,\n",
    "                        steps_per_epoch=int(len(tr_tr)/batch_size),#int(10740.75), \n",
    "                        validation_steps=len(tr_val))\n",
    "                        #validation_data=((test_images), test_labels)\n",
    "                        #use_multiprocessing=True)\n",
    "    #model.save(file_path)\n",
    "print(\"Trained Model saved  to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##model.save(\"imdb_NAS_mobile_save.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
