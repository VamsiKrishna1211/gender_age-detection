{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    " \n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from numpy import save, load\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras import optimizers, losses, activations, models\n",
    "from tensorflow.keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, \\\n",
    "    GlobalMaxPool2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, Lambda, Conv2D\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#!rm -rf ./logs/fit/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/sda4/vamsik1211/Data/git-repos/gender_age-detection'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K.set_floatx('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Croped_image(img,bb_data):\n",
    "    img_shape = img.shape\n",
    "    x = bb_data[0]\n",
    "    y = bb_data[1]\n",
    "    w = bb_data[2]\n",
    "    h = bb_data[3]\n",
    "    crop_img = img[y:y+h, x:x+w]\n",
    "    return crop_img\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.1)\n",
    "\n",
    "def augment(im_array):\n",
    "    im_array = datagen.random_transform(im_array)\n",
    "    return im_array\n",
    "\n",
    "\n",
    "def read_and_resize(dataFrame, input_shape=(224,224),aug=True):\n",
    "    #filepath = image_data.path.values[0]\n",
    "    images = []\n",
    "    for index in dataFrame.index :\n",
    "        im_cv = cv2.imread(dataFrame[\"path\"][index])\n",
    "        bb_data = (dataFrame[\"x\"][index],dataFrame[\"y\"][index],dataFrame[\"w\"][index],dataFrame[\"h\"][index])\n",
    "        im_cv = Get_Croped_image(im_cv,bb_data)\n",
    "        im_cv = cv2.resize(im_cv,input_shape)\n",
    "        im_array = np.array(im_cv)\n",
    "        im_cv = np.array(im_array / (np.max(im_array)+ 0.001))\n",
    "        if aug:\n",
    "            im_cv = augment(im_cv)\n",
    "        images.append(im_cv)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def gen(df, batch_size=4,input_shape=(224,224), aug=False):\n",
    "#     df = df.sample(frac=1)\n",
    "#     while True:\n",
    "#         for _, batch in enumerate([df[i:i+batch_size] for i in range(0,df.shape[0],batch_size)]):\n",
    "#             labels = np.array(batch.out_ages.values)\n",
    "#             labels = labels[..., np.newaxis]    \n",
    "#             images = np.array(read_and_resize(batch,aug=aug))\n",
    "#             yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(df, num_classes, input_shape, batch_size=4, aug=False):\n",
    "    df = df.sample(frac=1)\n",
    "    while True:\n",
    "        for _, batch in enumerate([df[i:i+batch_size] for i in range(0,df.shape[0],batch_size)]):\n",
    "            labels = np.array(batch.out_ages.values)\n",
    "            \n",
    "            #labels = labels[..., np.newaxis]\n",
    "            labels_categorical = []\n",
    "            for label in labels:\n",
    "                labels_categorical.append(to_categorical(label,num_classes=num_classes))\n",
    "            labels_categorical = np.array(labels_categorical)\n",
    "            #labels_categorical = labels_categorical[...,np.newaxis]\n",
    "            \n",
    "            #labels = labels[..., np.newaxis]    \n",
    "            images = np.array(read_and_resize(batch,input_shape=input_shape,aug=aug))\n",
    "            yield images, labels_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(optimizer,n_classes=1):\n",
    "\n",
    "#     base_model = keras.applications.nasnet.NASNetMobile(weights=\"./NASNet-mobile-no-top.h5\", include_top=False)\n",
    "\n",
    "#     #for layer in base_model.layers:\n",
    "#     #    layer.trainable = False\n",
    "\n",
    "#     x = base_model.output\n",
    "#     x = GlobalAveragePooling2D()(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     #x = Flatten()\n",
    "#     x = Dense(1000, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     x = Dense(750,activation=\"relu\")(x)\n",
    "#     x = Dense(350,activation=\"relu\")(x)\n",
    "#     x = Dense(100,activation=\"relu\")(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     if n_classes == 1:\n",
    "#         x = Dense(n_classes, activation=\"sigmoid\")(x)\n",
    "#     else:\n",
    "#         x = Dense(n_classes, activation=\"softmax\")(x)\n",
    "\n",
    "#     base_model = Model(base_model.input, x, name=\"base_model\")\n",
    "#     if n_classes == 1:\n",
    "#         base_model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=optimizer)\n",
    "#     else:\n",
    "#         base_model.compile(loss=\"sparse_categorical_crossentropy\", metrics=['acc'], optimizer=optimizer)\n",
    "\n",
    "    base_model = load_model(\"imdb_age_recog_weights.h5\")\n",
    "\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train and test CSV files \n",
      "Reading Done.\n",
      "Generating callback_list\n",
      "Done Generating callbacklist.\n",
      "generating Model\n",
      "WARNING:tensorflow:From /mnt/sda4/vamsik1211/Data/ML/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/sda4/vamsik1211/Data/ML/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/sda4/vamsik1211/Data/ML/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/sda4/vamsik1211/Data/ML/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/sda4/vamsik1211/Data/ML/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/sda4/vamsik1211/Data/ML/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/sda4/vamsik1211/Data/ML/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/sda4/vamsik1211/Data/ML/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done generating model\n"
     ]
    }
   ],
   "source": [
    "#device.reset()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_path = \"./Dataset-copy/\"\n",
    "\n",
    "    dict_age = {'(0, 2)' : 0,\n",
    "                '(3, 5)' : 1,\n",
    "                '(6, 10)' : 2,\n",
    "                '(11, 15)' : 3,\n",
    "                '(16, 20)' : 4,\n",
    "                '(21, 30)' : 5,\n",
    "                '(31, 40)' : 6,\n",
    "                '(41, 50)' : 7,\n",
    "                '(51, 60)' : 8,\n",
    "                '(61, 70)' : 9,\n",
    "                '(71, 80)' : 10,\n",
    "                 '(81, 90)' : 11,\n",
    "                 '(91, 100)' : 12}\n",
    "\n",
    "    bag = 3\n",
    "\n",
    "    all_indexes = list(range(5))\n",
    "    \n",
    "    accuracies = []\n",
    "    print(\"Reading train and test CSV files \")\n",
    "    train_df = pd.read_csv(\"croped_filter_expanded_data_age_range_update.csv\")\n",
    "    #test_df = pd.read_csv(\"test_gender_filtered_data_with_path.csv\")\n",
    "    tr_tr, tr_val = train_test_split(train_df, test_size=0.01)\n",
    "    \n",
    "    #tr_tr = tr_tr[:500]\n",
    "    \n",
    "    tr_unique_ages = tr_tr['out_ages'].unique()\n",
    "    num_classes = len(tr_unique_ages)\n",
    "    tr_unique_ages.sort()\n",
    "    #print(\"Unique ages are: \",val_unique_ages)\n",
    "    print(\"Reading Done.\")\n",
    "    cnt_ave = 0\n",
    "    predictions = 0\n",
    "#     print(\"Extracting test labels and test images from files\")\n",
    "#     test_images = load(\"imdb_test_images.npy\")\n",
    "#     test_labels = load(\"imdb_test_labels.npy\")\n",
    "#     print(\"Extracting Done.\")\n",
    "    #tr_tr, tr_val = train_test_split(train_df, test_size=0.1,random_state = 100)\n",
    "    file_path = \"imdb_age_recog_weights.h5\"\n",
    "    \n",
    "    print(\"Generating callback_list\")\n",
    "    \n",
    "#     log_dir=\"./logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#     tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    #early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)\n",
    "\n",
    "    reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "                                          mode=\"min\", \n",
    "                                          factor=0.1,\n",
    "                                          #cooldown=0,\n",
    "                                          patience=7,\n",
    "                                          verbose=1,\n",
    "                                          min_lr=0.00001)\n",
    "    log_dir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    callbacks_list = [checkpoint,\n",
    "                      reduce_on_plateau\n",
    "                      #tensorboard\n",
    "                      #tensorboard_callback\n",
    "                      #early\n",
    "                     ]  # early\n",
    "    #print(len(train_df[\"out_ages\"].unique()))\n",
    "    print(\"Done Generating callbacklist.\")\n",
    "    print(\"generating Model\")\n",
    "    optimizer = Adam(lr=0.00001)\n",
    "    model = get_model( optimizer,n_classes=len(train_df[\"out_ages\"].unique()))\n",
    "    print(\"Done generating model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fit_generator\n",
      "Epoch 1/200\n",
      "26433/33410 [======================>.......] - ETA: 49:27 - loss: 0.5291 - acc: 0.7985"
     ]
    }
   ],
   "source": [
    "print(\"Running Fit_generator\")\n",
    "batch_size = 11\n",
    "input_shape=(224,224)\n",
    "model.fit_generator(gen(tr_tr,num_classes, input_shape, batch_size=batch_size, aug=True), \n",
    "                        validation_data=gen(tr_val, num_classes, input_shape, aug=True), \n",
    "                        epochs=200, \n",
    "                        verbose=1, \n",
    "                        #workers=6,\n",
    "                        callbacks=callbacks_list,\n",
    "                        steps_per_epoch=int(len(tr_tr)/batch_size),#int(10740.75), \n",
    "                        validation_steps=int(len(tr_val)),\n",
    "                        #validation_data=((test_images), )\n",
    "                        #use_multiprocessing=True\n",
    "                       )\n",
    "    #model.save(file_path)\n",
    "print(\"Trained Model saved  to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##model.save(\"imdb_NAS_mobile_save.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"imdb_age_recog_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './logs/fit/20200611-145118'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0957ea700d3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlog_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./logs/fit/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y%m%d-%H%M%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './logs/fit/20200611-145118'"
     ]
    }
   ],
   "source": [
    "log_dir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "os.listdir(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1897be7dfd60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "K.clear_session().close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
