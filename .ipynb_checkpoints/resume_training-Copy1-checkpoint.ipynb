{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    " \n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from numpy import save, load\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras import optimizers, losses, activations, models\n",
    "from tensorflow.keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, \\\n",
    "    GlobalMaxPool2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, Lambda, Conv2D\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K.set_floatx('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Croped_image(img,bb_data):\n",
    "    img_shape = img.shape\n",
    "    x = bb_data[0]\n",
    "    y = bb_data[1]\n",
    "    w = bb_data[2]\n",
    "    h = bb_data[3]\n",
    "    crop_img = img[y:y+h, x:x+w]\n",
    "    return crop_img\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.1)\n",
    "\n",
    "def augment(im_array):\n",
    "    im_array = datagen.random_transform(im_array)\n",
    "    return im_array\n",
    "\n",
    "\n",
    "def read_and_resize(dataFrame, input_shape=(224,224),aug=True):\n",
    "    #filepath = image_data.path.values[0]\n",
    "    images = []\n",
    "    for index in dataFrame.index :\n",
    "        im_cv = cv2.imread(dataFrame[\"path\"][index])\n",
    "        bb_data = (dataFrame[\"x\"][index],dataFrame[\"y\"][index],dataFrame[\"w\"][index],dataFrame[\"h\"][index])\n",
    "        im_cv = Get_Croped_image(im_cv,bb_data)\n",
    "        im_cv = cv2.resize(im_cv,input_shape)\n",
    "        im_array = np.array(im_cv)\n",
    "        im_cv = np.array(im_array / (np.max(im_array)+ 0.001))\n",
    "        if aug:\n",
    "            im_cv = augment(im_cv)\n",
    "        images.append(im_cv)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen(df, batch_size=4,input_shape=(64,64), aug=False):\n",
    "    df = df.sample(frac=1)\n",
    "    while True:\n",
    "        for _, batch in enumerate([df[i:i+batch_size] for i in range(0,df.shape[0],batch_size)]):\n",
    "            labels = np.array(batch.out_ages.values)\n",
    "            labels = labels[..., np.newaxis]    \n",
    "            images = np.array(read_and_resize(batch,aug=aug))\n",
    "            yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(optimizer,n_classes=1):\n",
    "\n",
    "#     base_model = keras.applications.nasnet.NASNetMobile(weights=\"./NASNet-mobile-no-top.h5\", include_top=False)\n",
    "\n",
    "#     #for layer in base_model.layers:\n",
    "#     #    layer.trainable = False\n",
    "\n",
    "#     x = base_model.output\n",
    "#     x = GlobalAveragePooling2D()(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     #x = Flatten()\n",
    "#     x = Dense(1000, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     x = Dense(750,activation=\"relu\")(x)\n",
    "#     x = Dense(350,activation=\"relu\")(x)\n",
    "#     x = Dense(100,activation=\"relu\")(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     if n_classes == 1:\n",
    "#         x = Dense(n_classes, activation=\"sigmoid\")(x)\n",
    "#     else:\n",
    "#         x = Dense(n_classes, activation=\"softmax\")(x)\n",
    "\n",
    "#     base_model = Model(base_model.input, x, name=\"base_model\")\n",
    "#     if n_classes == 1:\n",
    "#         base_model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=optimizer)\n",
    "#     else:\n",
    "#         base_model.compile(loss=\"sparse_categorical_crossentropy\", metrics=['acc'], optimizer=optimizer)\n",
    "\n",
    "    base_model = load_model(\"imdb_age_recog_weights.h5\")\n",
    "\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train and test CSV files \n",
      "Reading Done.\n",
      "Generating callback_list\n",
      "Done Generating callbacklist.\n",
      "generating Model\n",
      "WARNING:tensorflow:From /mnt/sda5/vamsik1211/Data/ML/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/sda5/vamsik1211/Data/ML/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done generating model\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    base_path = \"./Dataset-copy/\"\n",
    "\n",
    "    dict_age = {'(0, 2)' : 0,\n",
    "                '(3, 5)' : 1,\n",
    "                '(6, 10)' : 2,\n",
    "                '(11, 15)' : 3,\n",
    "                '(16, 20)' : 4,\n",
    "                '(21, 30)' : 5,\n",
    "                '(31, 40)' : 6,\n",
    "                '(41, 50)' : 7,\n",
    "                '(51, 60)' : 8,\n",
    "                '(61, 70)' : 9,\n",
    "                '(71, 80)' : 10,\n",
    "                 '(81, 90)' : 11,\n",
    "                 '(91, 100)' : 12}\n",
    "\n",
    "    bag = 3\n",
    "\n",
    "    all_indexes = list(range(5))\n",
    "    \n",
    "    accuracies = []\n",
    "    print(\"Reading train and test CSV files \")\n",
    "    train_df = pd.read_csv(\"croped_filter_expanded_data.csv\")\n",
    "    #test_df = pd.read_csv(\"test_gender_filtered_data_with_path.csv\")\n",
    "    tr_tr, tr_val = train_test_split(train_df, test_size=0.0005, random_state=100)\n",
    "    tr_unique_ages = tr_tr['out_ages'].unique()\n",
    "    tr_unique_ages.sort()\n",
    "    #print(\"Unique ages are: \",val_unique_ages)\n",
    "    print(\"Reading Done.\")\n",
    "    cnt_ave = 0\n",
    "    predictions = 0\n",
    "#     print(\"Extracting test labels and test images from files\")\n",
    "#     test_images = load(\"imdb_test_images.npy\")\n",
    "#     test_labels = load(\"imdb_test_labels.npy\")\n",
    "#     print(\"Extracting Done.\")\n",
    "    #tr_tr, tr_val = train_test_split(train_df, test_size=0.1,random_state = 100)\n",
    "    file_path = \"imdb_age_recog_weights.h5\"\n",
    "    \n",
    "    print(\"Generating callback_list\")\n",
    "    \n",
    "#     log_dir=\"./logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#     tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    #early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)\n",
    "\n",
    "    reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "                                          mode=\"min\", \n",
    "                                          factor=0.1,\n",
    "                                          #cooldown=0,\n",
    "                                          patience=7,\n",
    "                                          verbose=1,\n",
    "                                          min_lr=0.0000001)\n",
    "\n",
    "    tensorboard = TensorBoard(log_dir='./logs/imdb_age_recog')\n",
    "\n",
    "    callbacks_list = [checkpoint,\n",
    "                      reduce_on_plateau,\n",
    "                      tensorboard\n",
    "                      #tensorboard_callback\n",
    "                      #early\n",
    "                     ]  # early\n",
    "    \n",
    "    print(\"Done Generating callbacklist.\")\n",
    "    print(\"generating Model\")\n",
    "    optimizer = Adam(lr=0.0001)\n",
    "    model = get_model( optimizer,n_classes=99)\n",
    "    print(\"Done generating model\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fit_generator\n",
      "Epoch 1/200\n",
      "11593/11594 [============================>.] - ETA: 0s - loss: 0.8032 - acc: 0.7420Epoch 1/200\n",
      "  185/11594 [..............................] - ETA: 14:12 - loss: 0.8512 - acc: 0.7084\n",
      "Epoch 00001: val_acc improved from -inf to 0.70867, saving model to imdb_age_recog_weights.h5\n",
      "11594/11594 [==============================] - 10837s 935ms/step - loss: 0.8032 - acc: 0.7421 - val_loss: 0.8509 - val_acc: 0.7087\n",
      "Epoch 2/200\n",
      "11593/11594 [============================>.] - ETA: 0s - loss: 0.7694 - acc: 0.7526Epoch 1/200\n",
      "  186/11594 [..............................] - ETA: 8:42 - loss: 0.8768 - acc: 0.7038\n",
      "Epoch 00002: val_acc did not improve from 0.70867\n",
      "11594/11594 [==============================] - 10504s 906ms/step - loss: 0.7694 - acc: 0.7526 - val_loss: 0.8768 - val_acc: 0.7038\n",
      "Epoch 3/200\n",
      "11593/11594 [============================>.] - ETA: 0s - loss: 0.7388 - acc: 0.7629Epoch 1/200\n",
      "  186/11594 [..............................] - ETA: 10:21 - loss: 0.7631 - acc: 0.7527\n",
      "Epoch 00003: val_acc improved from 0.70867 to 0.75272, saving model to imdb_age_recog_weights.h5\n",
      "11594/11594 [==============================] - 10750s 927ms/step - loss: 0.7388 - acc: 0.7629 - val_loss: 0.7631 - val_acc: 0.7527\n",
      "Epoch 4/200\n",
      " 7372/11594 [==================>...........] - ETA: 1:04:42 - loss: 0.7131 - acc: 0.7702"
     ]
    }
   ],
   "source": [
    "print(\"Running Fit_generator\")\n",
    "batch_size = 32\n",
    "input_shape=(64,64)\n",
    "model.fit_generator(gen(tr_tr,batch_size=batch_size, aug=True), \n",
    "                        validation_data=gen(tr_val), \n",
    "                        epochs=200, \n",
    "                        verbose=1, \n",
    "                        #workers=4,\n",
    "                        callbacks=callbacks_list,\n",
    "                        steps_per_epoch=int(len(tr_tr)/batch_size),#int(10740.75), \n",
    "                        validation_steps=len(tr_val))\n",
    "                        #validation_data=((test_images), test_labels)\n",
    "                        #use_multiprocessing=True)\n",
    "    #model.save(file_path)\n",
    "print(\"Trained Model saved  to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##model.save(\"imdb_NAS_mobile_save.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"croped_filter_expanded_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['path', 'out_ages', 'out_genders', 'face_scores', 'x', 'y', 'w', 'h'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
